{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.data.make_dataset import INDEX_SHEET_NAME,load_data\n",
    "from src.features.build_features import generate_features\n",
    "from src.models.LSTM import build_lstm_model, generate_train_val_data\n",
    "from src.models.metrics import LinearCorrelation, MeanAbsolutePercentageError, TheilU\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HangSeng Index Data',\n",
       " 'S&P500 Index Data',\n",
       " 'CSI300 Index Data',\n",
       " 'DJIA index Data',\n",
       " 'Nikkei 225 index Data',\n",
       " 'Nifty 50 index Data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_SHEET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ntime</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>CCI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>...</th>\n",
       "      <th>EMA20</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MTM6</th>\n",
       "      <th>MTM12</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SMI</th>\n",
       "      <th>WVAD</th>\n",
       "      <th>US dollar Index</th>\n",
       "      <th>Interbank Offered Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20080701</td>\n",
       "      <td>733590</td>\n",
       "      <td>4039.75</td>\n",
       "      <td>4075.40</td>\n",
       "      <td>3878.20</td>\n",
       "      <td>3896.75</td>\n",
       "      <td>164469220</td>\n",
       "      <td>-201.56</td>\n",
       "      <td>-180.03</td>\n",
       "      <td>197.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.058946</td>\n",
       "      <td>4128.49</td>\n",
       "      <td>4253.415</td>\n",
       "      <td>-369.65</td>\n",
       "      <td>-620.35</td>\n",
       "      <td>-13.733369</td>\n",
       "      <td>-0.149627</td>\n",
       "      <td>-828023961.0</td>\n",
       "      <td>72.34</td>\n",
       "      <td>8.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20080702</td>\n",
       "      <td>733591</td>\n",
       "      <td>3895.30</td>\n",
       "      <td>4107.15</td>\n",
       "      <td>3848.25</td>\n",
       "      <td>4093.35</td>\n",
       "      <td>199920144</td>\n",
       "      <td>-199.63</td>\n",
       "      <td>-131.91</td>\n",
       "      <td>258.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4357.277142</td>\n",
       "      <td>4096.63</td>\n",
       "      <td>4204.510</td>\n",
       "      <td>-97.75</td>\n",
       "      <td>-479.15</td>\n",
       "      <td>-10.478950</td>\n",
       "      <td>-0.091225</td>\n",
       "      <td>-561033032.0</td>\n",
       "      <td>71.99</td>\n",
       "      <td>7.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20080703</td>\n",
       "      <td>733592</td>\n",
       "      <td>4094.60</td>\n",
       "      <td>4097.35</td>\n",
       "      <td>3874.85</td>\n",
       "      <td>3925.75</td>\n",
       "      <td>154573765</td>\n",
       "      <td>-209.21</td>\n",
       "      <td>-129.55</td>\n",
       "      <td>222.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4316.179319</td>\n",
       "      <td>4018.61</td>\n",
       "      <td>4146.660</td>\n",
       "      <td>-326.90</td>\n",
       "      <td>-727.25</td>\n",
       "      <td>-15.629701</td>\n",
       "      <td>-0.097020</td>\n",
       "      <td>-726253640.3</td>\n",
       "      <td>72.73</td>\n",
       "      <td>6.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080704</td>\n",
       "      <td>733593</td>\n",
       "      <td>3926.65</td>\n",
       "      <td>4033.50</td>\n",
       "      <td>3896.40</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>152045352</td>\n",
       "      <td>-207.14</td>\n",
       "      <td>-111.08</td>\n",
       "      <td>137.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4287.590812</td>\n",
       "      <td>3994.48</td>\n",
       "      <td>4113.505</td>\n",
       "      <td>-299.85</td>\n",
       "      <td>-566.40</td>\n",
       "      <td>-12.360335</td>\n",
       "      <td>-0.058691</td>\n",
       "      <td>-548766472.1</td>\n",
       "      <td>72.71</td>\n",
       "      <td>6.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20080707</td>\n",
       "      <td>733596</td>\n",
       "      <td>4002.00</td>\n",
       "      <td>4114.50</td>\n",
       "      <td>4002.00</td>\n",
       "      <td>4030.00</td>\n",
       "      <td>125737237</td>\n",
       "      <td>-202.03</td>\n",
       "      <td>-80.86</td>\n",
       "      <td>112.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4263.058354</td>\n",
       "      <td>3992.37</td>\n",
       "      <td>4089.865</td>\n",
       "      <td>-106.65</td>\n",
       "      <td>-474.25</td>\n",
       "      <td>-10.528945</td>\n",
       "      <td>-0.038439</td>\n",
       "      <td>-486195115.1</td>\n",
       "      <td>72.71</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Ntime  Open Price  High Price  Low price  Closing Price  \\\n",
       "0  20080701  733590     4039.75     4075.40    3878.20        3896.75   \n",
       "1  20080702  733591     3895.30     4107.15    3848.25        4093.35   \n",
       "2  20080703  733592     4094.60     4097.35    3874.85        3925.75   \n",
       "3  20080704  733593     3926.65     4033.50    3896.40        4016.00   \n",
       "4  20080707  733596     4002.00     4114.50    4002.00        4030.00   \n",
       "\n",
       "      Volume    MACD     CCI    ATR  ...        EMA20      MA5      MA10  \\\n",
       "0  164469220 -201.56 -180.03  197.2  ...  4385.058946  4128.49  4253.415   \n",
       "1  199920144 -199.63 -131.91  258.9  ...  4357.277142  4096.63  4204.510   \n",
       "2  154573765 -209.21 -129.55  222.5  ...  4316.179319  4018.61  4146.660   \n",
       "3  152045352 -207.14 -111.08  137.1  ...  4287.590812  3994.48  4113.505   \n",
       "4  125737237 -202.03  -80.86  112.5  ...  4263.058354  3992.37  4089.865   \n",
       "\n",
       "     MTM6   MTM12        ROC       SMI         WVAD  US dollar Index  \\\n",
       "0 -369.65 -620.35 -13.733369 -0.149627 -828023961.0            72.34   \n",
       "1  -97.75 -479.15 -10.478950 -0.091225 -561033032.0            71.99   \n",
       "2 -326.90 -727.25 -15.629701 -0.097020 -726253640.3            72.73   \n",
       "3 -299.85 -566.40 -12.360335 -0.058691 -548766472.1            72.71   \n",
       "4 -106.65 -474.25 -10.528945 -0.038439 -486195115.1            72.71   \n",
       "\n",
       "   Interbank Offered Rate  \n",
       "0                   8.706  \n",
       "1                   7.730  \n",
       "2                   6.400  \n",
       "3                   6.210  \n",
       "4                   9.000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = load_data(sheet_name=INDEX_SHEET_NAME[-1])\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following sections are training process of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WSAE-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DJIA index Data part!\n",
      ">>>>201010 finished!<<<<\n",
      ">>>>201101 finished!<<<<\n",
      ">>>>201104 finished!<<<<\n",
      ">>>>201107 finished!<<<<\n",
      ">>>>201110 finished!<<<<\n",
      ">>>>201201 finished!<<<<\n",
      ">>>>201204 finished!<<<<\n",
      ">>>>201207 finished!<<<<\n",
      ">>>>201210 finished!<<<<\n",
      ">>>>201301 finished!<<<<\n",
      ">>>>201304 finished!<<<<\n",
      ">>>>201307 finished!<<<<\n",
      ">>>>201310 finished!<<<<\n",
      ">>>>201401 finished!<<<<\n",
      ">>>>201404 finished!<<<<\n",
      ">>>>201407 finished!<<<<\n",
      ">>>>201410 finished!<<<<\n",
      ">>>>201501 finished!<<<<\n",
      ">>>>201504 finished!<<<<\n",
      ">>>>201507 finished!<<<<\n",
      ">>>>201510 finished!<<<<\n",
      ">>>>201601 finished!<<<<\n",
      ">>>>201604 finished!<<<<\n",
      ">>>>201607 finished!<<<<\n",
      ">>>> Feature generation complete! <<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1508e-04 - mean_absolute_percentage_error: 2.8511 - mape: 0.0285 - r: 0.9344 - theil_u: 0.0161\n",
      ">>>>DJIA index Data 201010 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0045 - mean_absolute_percentage_error: 5.2503 - mape: 0.0525 - r: 0.9000 - theil_u: 0.0293\n",
      ">>>>DJIA index Data 201101 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 6.4762 - mape: 0.0648 - r: 0.9055 - theil_u: 0.0357\n",
      ">>>>DJIA index Data 201104 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 9.2930 - mape: 0.0929 - r: 0.8964 - theil_u: 0.0501\n",
      ">>>>DJIA index Data 201107 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 7.8714 - mape: 0.0787 - r: 0.3861 - theil_u: 0.0550\n",
      ">>>>DJIA index Data 201110 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 8.6686 - mape: 0.0867 - r: 0.8999 - theil_u: 0.0516\n",
      ">>>>DJIA index Data 201201 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0161 - mean_absolute_percentage_error: 11.5559 - mape: 0.1156 - r: 0.8488 - theil_u: 0.0687\n",
      ">>>>DJIA index Data 201204 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mean_absolute_percentage_error: 3.4325 - mape: 0.0343 - r: 0.9610 - theil_u: 0.0216\n",
      ">>>>DJIA index Data 201207 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - mean_absolute_percentage_error: 4.9244 - mape: 0.0492 - r: 0.7037 - theil_u: 0.0274\n",
      ">>>>DJIA index Data 201210 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_absolute_percentage_error: 5.5345 - mape: 0.0553 - r: 0.9817 - theil_u: 0.0340\n",
      ">>>>DJIA index Data 201301 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0654 - mean_absolute_percentage_error: 16.5007 - mape: 0.1650 - r: 0.8884 - theil_u: 0.0953\n",
      ">>>>DJIA index Data 201304 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - mean_absolute_percentage_error: 2.8890 - mape: 0.0289 - r: 0.8526 - theil_u: 0.0168\n",
      ">>>>DJIA index Data 201307 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0017 - mean_absolute_percentage_error: 3.0085 - mape: 0.0301 - r: 0.8698 - theil_u: 0.0193\n",
      ">>>>DJIA index Data 201310 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 7.9743 - mape: 0.0797 - r: 0.9071 - theil_u: 0.0434\n",
      ">>>>DJIA index Data 201401 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7755e-04 - mean_absolute_percentage_error: 2.2773 - mape: 0.0228 - r: 0.8410 - theil_u: 0.0154\n",
      ">>>>DJIA index Data 201404 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0044 - mean_absolute_percentage_error: 5.4641 - mape: 0.0546 - r: 0.7872 - theil_u: 0.0312\n",
      ">>>>DJIA index Data 201407 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0163 - mean_absolute_percentage_error: 9.8366 - mape: 0.0984 - r: 0.8268 - theil_u: 0.0610\n",
      ">>>>DJIA index Data 201410 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0201 - mean_absolute_percentage_error: 11.9816 - mape: 0.1198 - r: 0.7320 - theil_u: 0.0675\n",
      ">>>>DJIA index Data 201501 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3885e-04 - mean_absolute_percentage_error: 2.3756 - mape: 0.0238 - r: 0.3696 - theil_u: 0.0145\n",
      ">>>>DJIA index Data 201504 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0045 - mean_absolute_percentage_error: 9.0015 - mape: 0.0900 - r: 0.9419 - theil_u: 0.0474\n",
      ">>>>DJIA index Data 201507 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.8126 - mape: 0.0981 - r: 0.7623 - theil_u: 0.0554\n",
      ">>>>DJIA index Data 201510 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0377 - mean_absolute_percentage_error: 27.4725 - mape: 0.2747 - r: -0.6313 - theil_u: 0.1966\n",
      ">>>>DJIA index Data 201601 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048 - mean_absolute_percentage_error: 7.2429 - mape: 0.0724 - r: 0.7879 - theil_u: 0.0441\n",
      ">>>>DJIA index Data 201604 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0117 - mean_absolute_percentage_error: 9.5879 - mape: 0.0959 - r: 0.7638 - theil_u: 0.0551\n",
      ">>>>DJIA index Data 201607 done!<<<<\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "EPOCHS = 500 #0\n",
    "past_history = 4\n",
    "\n",
    "for index in INDEX_SHEET_NAME:\n",
    "    print(f\"Start {index} part!\")\n",
    "    result_dict[index] = dict()\n",
    "\n",
    "    data_dir = f'../data/processed/wsae/{index}'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raw = load_data(sheet_name=index)\n",
    "        generate_features(raw, index)\n",
    "    \n",
    "    train_lst = os.listdir(data_dir)\n",
    "    train_lst.sort()\n",
    "    for name in train_lst:\n",
    "        x_train = np.load(data_dir + f'/{name}/X_train.npy')\n",
    "        y_train = np.load(data_dir + f'/{name}/Y_train.npy')\n",
    "        x_val = np.load(data_dir + f'/{name}/X_val.npy')\n",
    "        y_val = np.load(data_dir + f'/{name}/Y_val.npy')\n",
    "        x_test = np.load(data_dir + f'/{name}/X_test.npy')\n",
    "        y_test = np.load(data_dir + f'/{name}/Y_test.npy')\n",
    "\n",
    "        train_data, val_data, test_data = generate_train_val_data(\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "            past_history=4, batch_size=60\n",
    "        )\n",
    "\n",
    "\n",
    "        model_save_dir = f'../models/{index}/{name}'\n",
    "        if not os.path.exists(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "        if not os.path.exists(model_save_dir+'/wase-lstm_config.json') \\\n",
    "            or not os.path.exists(model_save_dir+'/wase-lstm_weights.h5'):\n",
    "            print(\"No existing model, start to train!\")\n",
    "            lstm = build_lstm_model(inputs_shape=[4, 10],\n",
    "                                    layers=5,\n",
    "                                    units=[64, 64, 64, 64, 64],\n",
    "                                    learning_rate=0.05)\n",
    "            lstm.fit(train_data,\n",
    "                     epochs=EPOCHS,\n",
    "                     steps_per_epoch=(y_train.shape[0] // 60),\n",
    "                     validation_data=val_data,\n",
    "                     validation_steps=1,\n",
    "                     verbose=0)\n",
    "            json_config = lstm.to_json()\n",
    "\n",
    "            with open(model_save_dir+'/wase-lstm_config.json', 'w') as json_file:\n",
    "                json_file.write(json_config)\n",
    "            # Save weights to disk\n",
    "            lstm.save_weights(model_save_dir+'/wase-lstm_weights.h5')\n",
    "            print(\"Model Saved!\")\n",
    "        else:\n",
    "            with open(model_save_dir+'/wase-lstm_config.json') as json_file:\n",
    "                json_config = json_file.read()\n",
    "            lstm = tf.keras.models.model_from_json(json_config)\n",
    "            lstm.compile(loss='mse',\n",
    "                              optimizer='Adam',\n",
    "                              metrics=[\n",
    "                                  tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "                                  MeanAbsolutePercentageError(),\n",
    "                                  LinearCorrelation(),\n",
    "                                  TheilU()],\n",
    "                              lr=0.05\n",
    "                              )\n",
    "            lstm.load_weights(model_save_dir+'/wase-lstm_weights.h5')\n",
    "\n",
    "            print(\"Model Loaded!\")\n",
    "\n",
    "        result_dict[index][name] = lstm.evaluate(test_data, steps=1)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        print(f\">>>>{index} {name} done!<<<<\")\n",
    "    try:\n",
    "        with open(f'./wsae-lstm/{index}_train_result.pickle', 'wb') as handle:\n",
    "            pickle.dump(result_dict[index], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print('fail to save!')\n",
    "\n",
    "with open(f'./wsae-lstm/train_result.pickle', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DJIA index Data part!\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - mean_absolute_percentage_error: 3.5034 - mape: 0.0350 - r: 0.8963 - theil_u: 0.0201\n",
      ">>>>DJIA index Data 201010 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 6.6325 - mape: 0.0663 - r: 0.8050 - theil_u: 0.0370\n",
      ">>>>DJIA index Data 201101 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0130 - mean_absolute_percentage_error: 9.2717 - mape: 0.0927 - r: 0.6966 - theil_u: 0.0518\n",
      ">>>>DJIA index Data 201104 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0032 - mean_absolute_percentage_error: 5.5508 - mape: 0.0555 - r: 0.9062 - theil_u: 0.0335\n",
      ">>>>DJIA index Data 201107 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 8.4291 - mape: 0.0843 - r: 0.3574 - theil_u: 0.0533\n",
      ">>>>DJIA index Data 201110 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - mean_absolute_percentage_error: 3.0499 - mape: 0.0305 - r: 0.9080 - theil_u: 0.0180\n",
      ">>>>DJIA index Data 201201 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - mean_absolute_percentage_error: 4.8421 - mape: 0.0484 - r: 0.8751 - theil_u: 0.0281\n",
      ">>>>DJIA index Data 201204 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - mean_absolute_percentage_error: 2.9397 - mape: 0.0294 - r: 0.9181 - theil_u: 0.0184\n",
      ">>>>DJIA index Data 201207 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - mean_absolute_percentage_error: 3.3355 - mape: 0.0334 - r: 0.8456 - theil_u: 0.0210\n",
      ">>>>DJIA index Data 201210 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0030 - mean_absolute_percentage_error: 3.8637 - mape: 0.0386 - r: 0.9457 - theil_u: 0.0237\n",
      ">>>>DJIA index Data 201301 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0499 - mean_absolute_percentage_error: 14.3691 - mape: 0.1437 - r: 0.6208 - theil_u: 0.0823\n",
      ">>>>DJIA index Data 201304 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0137 - mean_absolute_percentage_error: 9.2621 - mape: 0.0926 - r: 0.8866 - theil_u: 0.0515\n",
      ">>>>DJIA index Data 201307 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 5.8217 - mape: 0.0582 - r: 0.9190 - theil_u: 0.0358\n",
      ">>>>DJIA index Data 201310 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0043 - mean_absolute_percentage_error: 5.4274 - mape: 0.0543 - r: 0.8868 - theil_u: 0.0306\n",
      ">>>>DJIA index Data 201401 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mean_absolute_percentage_error: 3.3465 - mape: 0.0335 - r: 0.8397 - theil_u: 0.0205\n",
      ">>>>DJIA index Data 201404 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0018 - mean_absolute_percentage_error: 3.1945 - mape: 0.0319 - r: 0.7875 - theil_u: 0.0198\n",
      ">>>>DJIA index Data 201407 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0396 - mean_absolute_percentage_error: 15.5005 - mape: 0.1550 - r: 0.7545 - theil_u: 0.0985\n",
      ">>>>DJIA index Data 201410 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0334 - mean_absolute_percentage_error: 15.6450 - mape: 0.1564 - r: 0.5756 - theil_u: 0.0887\n",
      ">>>>DJIA index Data 201501 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mean_absolute_percentage_error: 3.6627 - mape: 0.0366 - r: 0.3074 - theil_u: 0.0219\n",
      ">>>>DJIA index Data 201504 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 10.5376 - mape: 0.1054 - r: 0.9090 - theil_u: 0.0584\n",
      ">>>>DJIA index Data 201507 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048 - mean_absolute_percentage_error: 7.0247 - mape: 0.0702 - r: 0.7464 - theil_u: 0.0432\n",
      ">>>>DJIA index Data 201510 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0604 - mean_absolute_percentage_error: 45.1537 - mape: 0.4260 - r: 0.9220 - theil_u: 0.2390\n",
      ">>>>DJIA index Data 201601 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 10.6041 - mape: 0.1060 - r: 0.4615 - theil_u: 0.0573\n",
      ">>>>DJIA index Data 201604 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 6.7932 - mape: 0.0679 - r: 0.8322 - theil_u: 0.0428\n",
      ">>>>DJIA index Data 201607 done!<<<<\n"
     ]
    }
   ],
   "source": [
    "result_dict=dict()\n",
    "EPOCHS = 500 #0\n",
    "past_history = 4\n",
    "\n",
    "for index in INDEX_SHEET_NAME:\n",
    "    print(f\"Start {index} part!\")\n",
    "    result_dict[index] = dict()\n",
    "\n",
    "    data_dir = f'../data/processed/wavelet/{index}'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raw = load_data(sheet_name=index)\n",
    "        generate_features(raw, index)\n",
    "    \n",
    "    train_lst = os.listdir(data_dir)\n",
    "    train_lst.sort()\n",
    "    for name in train_lst:\n",
    "        x_train = np.load(data_dir + f'/{name}/X_train.npy')\n",
    "        y_train = np.load(data_dir + f'/{name}/Y_train.npy')\n",
    "        x_val = np.load(data_dir + f'/{name}/X_val.npy')\n",
    "        y_val = np.load(data_dir + f'/{name}/Y_val.npy')\n",
    "        x_test = np.load(data_dir + f'/{name}/X_test.npy')\n",
    "        y_test = np.load(data_dir + f'/{name}/Y_test.npy')\n",
    "\n",
    "        train_data, val_data, test_data = generate_train_val_data(\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "            past_history=4, batch_size=60\n",
    "        )\n",
    "\n",
    "\n",
    "        model_save_dir = f'../models/{index}/{name}'\n",
    "        config_filename = '/wlstm_config.json'\n",
    "        weight_filename = '/wlstm_weights.h5'\n",
    "\n",
    "        if not os.path.exists(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "        if not os.path.exists(model_save_dir+config_filename) \\\n",
    "            or not os.path.exists(model_save_dir+weight_filename):\n",
    "            print(\"No existing model, start to train!\")\n",
    "            lstm = build_lstm_model(inputs_shape=[4, 19],\n",
    "                                    layers=5,\n",
    "                                    units=[64, 64, 64, 64, 64],\n",
    "                                    learning_rate=0.05)\n",
    "            lstm.fit(train_data,\n",
    "                     epochs=EPOCHS,\n",
    "                     steps_per_epoch=(y_train.shape[0] // 60),\n",
    "                     validation_data=val_data,\n",
    "                     validation_steps=1,\n",
    "                     verbose=0)\n",
    "            json_config = lstm.to_json()\n",
    "\n",
    "            with open(model_save_dir+config_filename, 'w') as json_file:\n",
    "                json_file.write(json_config)\n",
    "            # Save weights to disk\n",
    "            lstm.save_weights(model_save_dir+weight_filename)\n",
    "            print(\"Model Saved!\")\n",
    "        else:\n",
    "            with open(model_save_dir+config_filename) as json_file:\n",
    "                json_config = json_file.read()\n",
    "            lstm = tf.keras.models.model_from_json(json_config)\n",
    "            lstm.compile(loss='mse',\n",
    "                              optimizer='Adam',\n",
    "                              metrics=[\n",
    "                                  tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "                                  MeanAbsolutePercentageError(),\n",
    "                                  LinearCorrelation(),\n",
    "                                  TheilU()],\n",
    "                              lr=0.05\n",
    "                              )\n",
    "            lstm.load_weights(model_save_dir+weight_filename)\n",
    "\n",
    "            print(\"Model Loaded!\")\n",
    "\n",
    "        result_dict[index][name] = lstm.evaluate(test_data, steps=1)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        print(f\">>>>{index} {name} done!<<<<\")\n",
    "    try:\n",
    "        with open(f'./wlstm/{index}_train_result.pickle', 'wb') as handle:\n",
    "            pickle.dump(result_dict[index], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print('fail to save!')\n",
    "\n",
    "with open(f'./wlstm/train_result.pickle', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAE-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Nifty 50 index Data part!\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0116 - mean_absolute_percentage_error: 8.5186 - mape: 0.0852 - r: 0.9339 - theil_u: 0.0456\n",
      ">>>>Nifty 50 index Data 201010 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - mean_absolute_percentage_error: 5.4680 - mape: 0.0547 - r: 0.8130 - theil_u: 0.0329\n",
      ">>>>Nifty 50 index Data 201101 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0113 - mean_absolute_percentage_error: 12.4645 - mape: 0.1246 - r: 0.3328 - theil_u: 0.0628\n",
      ">>>>Nifty 50 index Data 201104 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - mean_absolute_percentage_error: 4.5141 - mape: 0.0451 - r: 0.9159 - theil_u: 0.0266\n",
      ">>>>Nifty 50 index Data 201107 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0299 - mean_absolute_percentage_error: 43.8632 - mape: 0.4386 - r: 0.8883 - theil_u: 0.1705\n",
      ">>>>Nifty 50 index Data 201110 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - mean_absolute_percentage_error: 18.4425 - mape: 0.1844 - r: 0.9060 - theil_u: 0.0705\n",
      ">>>>Nifty 50 index Data 201201 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0030 - mean_absolute_percentage_error: 17.6195 - mape: 0.1762 - r: 0.8791 - theil_u: 0.1031\n",
      ">>>>Nifty 50 index Data 201204 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mean_absolute_percentage_error: 7.5082 - mape: 0.0751 - r: 0.9193 - theil_u: 0.0505\n",
      ">>>>Nifty 50 index Data 201207 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - mean_absolute_percentage_error: 8.0019 - mape: 0.0800 - r: 0.8579 - theil_u: 0.0507\n",
      ">>>>Nifty 50 index Data 201210 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - mean_absolute_percentage_error: 6.1017 - mape: 0.0610 - r: 0.9438 - theil_u: 0.0367\n",
      ">>>>Nifty 50 index Data 201301 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mean_absolute_percentage_error: 3.9573 - mape: 0.0396 - r: 0.9833 - theil_u: 0.0234\n",
      ">>>>Nifty 50 index Data 201304 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 9.7572 - mape: 0.0976 - r: 0.9393 - theil_u: 0.0574\n",
      ">>>>Nifty 50 index Data 201307 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0303 - mean_absolute_percentage_error: 16.6786 - mape: 0.1668 - r: 0.6261 - theil_u: 0.0962\n",
      ">>>>Nifty 50 index Data 201310 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 6.1496 - mape: 0.0615 - r: 0.9481 - theil_u: 0.0432\n",
      ">>>>Nifty 50 index Data 201401 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0909 - mean_absolute_percentage_error: 17.6236 - mape: 0.1762 - r: 0.9130 - theil_u: 0.1157\n",
      ">>>>Nifty 50 index Data 201404 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2178 - mean_absolute_percentage_error: 28.8121 - mape: 0.2881 - r: 0.6023 - theil_u: 0.1718\n",
      ">>>>Nifty 50 index Data 201407 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0519 - mean_absolute_percentage_error: 17.8872 - mape: 0.1789 - r: 0.7727 - theil_u: 0.1017\n",
      ">>>>Nifty 50 index Data 201410 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0399 - mean_absolute_percentage_error: 16.3860 - mape: 0.1639 - r: 0.7855 - theil_u: 0.0922\n",
      ">>>>Nifty 50 index Data 201501 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0037 - mean_absolute_percentage_error: 5.2835 - mape: 0.0528 - r: 0.1377 - theil_u: 0.0330\n",
      ">>>>Nifty 50 index Data 201504 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 10.9917 - mape: 0.1099 - r: 0.3844 - theil_u: 0.0636\n",
      ">>>>Nifty 50 index Data 201507 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0198 - mean_absolute_percentage_error: 19.8095 - mape: 0.1981 - r: 0.7199 - theil_u: 0.0913\n",
      ">>>>Nifty 50 index Data 201510 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0518 - mean_absolute_percentage_error: 45.5330 - mape: 0.4553 - r: -0.1754 - theil_u: 0.1893\n",
      ">>>>Nifty 50 index Data 201601 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - mean_absolute_percentage_error: 5.7818 - mape: 0.0578 - r: 0.7829 - theil_u: 0.0370\n",
      ">>>>Nifty 50 index Data 201604 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - mean_absolute_percentage_error: 3.7330 - mape: 0.0373 - r: 0.9507 - theil_u: 0.0223\n",
      ">>>>Nifty 50 index Data 201607 done!<<<<\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "EPOCHS = 500 #0\n",
    "past_history = 4\n",
    "\n",
    "for index in INDEX_SHEET_NAME:\n",
    "    print(f\"Start {index} part!\")\n",
    "    result_dict[index] = dict()\n",
    "\n",
    "    data_dir = f'../data/processed/sae/{index}'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raw = load_data(sheet_name=index)\n",
    "        generate_features(raw, index)\n",
    "    \n",
    "    train_lst = os.listdir(data_dir)\n",
    "    train_lst.sort()\n",
    "    for name in train_lst:\n",
    "        x_train = np.load(data_dir + f'/{name}/X_train.npy')\n",
    "        y_train = np.load(data_dir + f'/{name}/Y_train.npy')\n",
    "        x_val = np.load(data_dir + f'/{name}/X_val.npy')\n",
    "        y_val = np.load(data_dir + f'/{name}/Y_val.npy')\n",
    "        x_test = np.load(data_dir + f'/{name}/X_test.npy')\n",
    "        y_test = np.load(data_dir + f'/{name}/Y_test.npy')\n",
    "\n",
    "        train_data, val_data, test_data = generate_train_val_data(\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "            past_history=4, batch_size=60\n",
    "        )\n",
    "\n",
    "\n",
    "        model_save_dir = f'../models/{index}/{name}'\n",
    "        config_filename = '/sae-lstm_config.json'\n",
    "        weight_filename = '/sae-lstm_weights.h5'\n",
    "\n",
    "        if not os.path.exists(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "#         if not os.path.exists(model_save_dir+config_filename) \\\n",
    "#             or not os.path.exists(model_save_dir+weight_filename):\n",
    "        if True:\n",
    "            print(\"No existing model, start to train!\")\n",
    "            lstm = build_lstm_model(inputs_shape=[4, 10],\n",
    "                                    layers=5,\n",
    "                                    units=[64, 64, 64, 64, 64],\n",
    "                                    learning_rate=0.05)\n",
    "            lstm.fit(train_data,\n",
    "                     epochs=EPOCHS,\n",
    "                     steps_per_epoch=(y_train.shape[0] // 60),\n",
    "                     validation_data=val_data,\n",
    "                     validation_steps=1,\n",
    "                     verbose=0)\n",
    "            json_config = lstm.to_json()\n",
    "\n",
    "            with open(model_save_dir+config_filename, 'w') as json_file:\n",
    "                json_file.write(json_config)\n",
    "            # Save weights to disk\n",
    "            lstm.save_weights(model_save_dir+weight_filename)\n",
    "            print(\"Model Saved!\")\n",
    "        else:\n",
    "            with open(model_save_dir+config_filename) as json_file:\n",
    "                json_config = json_file.read()\n",
    "            lstm = tf.keras.models.model_from_json(json_config)\n",
    "            lstm.compile(loss='mse',\n",
    "                              optimizer='Adam',\n",
    "                              metrics=[\n",
    "                                  tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "                                  MeanAbsolutePercentageError(),\n",
    "                                  LinearCorrelation(),\n",
    "                                  TheilU()],\n",
    "                              lr=0.05\n",
    "                              )\n",
    "            lstm.load_weights(model_save_dir+weight_filename)\n",
    "\n",
    "            print(\"Model Loaded!\")\n",
    "\n",
    "        result_dict[index][name] = lstm.evaluate(test_data, steps=1)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        print(f\">>>>{index} {name} done!<<<<\")\n",
    "    try:\n",
    "        with open(f'./sae-lstm/{index}_train_result.pickle', 'wb') as handle:\n",
    "            pickle.dump(result_dict[index], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print('fail to save!')\n",
    "\n",
    "with open(f'./sae-lstm/train_result.pickle', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DJIA index Data part!\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9012e-04 - mean_absolute_percentage_error: 1.6065 - mape: 0.0161 - r: 0.9727 - theil_u: 0.0095\n",
      ">>>>DJIA index Data 201010 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0111 - mean_absolute_percentage_error: 8.5548 - mape: 0.0855 - r: 0.8294 - theil_u: 0.0466\n",
      ">>>>DJIA index Data 201101 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 7.5488 - mape: 0.0755 - r: 0.9439 - theil_u: 0.0404\n",
      ">>>>DJIA index Data 201104 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.4571e-04 - mean_absolute_percentage_error: 2.8125 - mape: 0.0281 - r: 0.9823 - theil_u: 0.0173\n",
      ">>>>DJIA index Data 201107 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 9.5801 - mape: 0.0958 - r: 0.3926 - theil_u: 0.0711\n",
      ">>>>DJIA index Data 201110 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - mean_absolute_percentage_error: 2.8052 - mape: 0.0281 - r: 0.9583 - theil_u: 0.0189\n",
      ">>>>DJIA index Data 201201 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mean_absolute_percentage_error: 3.3786 - mape: 0.0338 - r: 0.9815 - theil_u: 0.0194\n",
      ">>>>DJIA index Data 201204 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0329e-04 - mean_absolute_percentage_error: 1.6563 - mape: 0.0166 - r: 0.9856 - theil_u: 0.0104\n",
      ">>>>DJIA index Data 201207 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7815e-04 - mean_absolute_percentage_error: 1.5307 - mape: 0.0153 - r: 0.9761 - theil_u: 0.0087\n",
      ">>>>DJIA index Data 201210 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035 - mean_absolute_percentage_error: 4.0220 - mape: 0.0402 - r: 0.9818 - theil_u: 0.0263\n",
      ">>>>DJIA index Data 201301 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0349 - mean_absolute_percentage_error: 11.9580 - mape: 0.1196 - r: 0.8176 - theil_u: 0.0679\n",
      ">>>>DJIA index Data 201304 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0144 - mean_absolute_percentage_error: 9.9828 - mape: 0.0998 - r: 0.9587 - theil_u: 0.0530\n",
      ">>>>DJIA index Data 201307 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 5.7908 - mape: 0.0579 - r: 0.9713 - theil_u: 0.0343\n",
      ">>>>DJIA index Data 201310 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0047 - mean_absolute_percentage_error: 6.1656 - mape: 0.0617 - r: 0.9684 - theil_u: 0.0324\n",
      ">>>>DJIA index Data 201401 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2899e-04 - mean_absolute_percentage_error: 1.4108 - mape: 0.0141 - r: 0.9621 - theil_u: 0.0089\n",
      ">>>>DJIA index Data 201404 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mean_absolute_percentage_error: 3.4057 - mape: 0.0341 - r: 0.9101 - theil_u: 0.0200\n",
      ">>>>DJIA index Data 201407 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0338 - mean_absolute_percentage_error: 15.9510 - mape: 0.1595 - r: 0.8987 - theil_u: 0.0907\n",
      ">>>>DJIA index Data 201410 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0194 - mean_absolute_percentage_error: 11.0252 - mape: 0.1103 - r: 0.1957 - theil_u: 0.0660\n",
      ">>>>DJIA index Data 201501 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - mean_absolute_percentage_error: 3.3995 - mape: 0.0340 - r: 0.8048 - theil_u: 0.0197\n",
      ">>>>DJIA index Data 201504 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_absolute_percentage_error: 11.5328 - mape: 0.1153 - r: 0.9793 - theil_u: 0.0539\n",
      ">>>>DJIA index Data 201507 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mean_absolute_percentage_error: 3.6887 - mape: 0.0369 - r: 0.8938 - theil_u: 0.0239\n",
      ">>>>DJIA index Data 201510 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 19.3430 - mape: 0.1934 - r: 0.8790 - theil_u: 0.1048\n",
      ">>>>DJIA index Data 201601 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - mean_absolute_percentage_error: 4.1337 - mape: 0.0413 - r: 0.9176 - theil_u: 0.0237\n",
      ">>>>DJIA index Data 201604 done!<<<<\n",
      "No existing model, start to train!\n",
      "Model Saved!\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - mean_absolute_percentage_error: 3.1744 - mape: 0.0317 - r: 0.9230 - theil_u: 0.0190\n",
      ">>>>DJIA index Data 201607 done!<<<<\n"
     ]
    }
   ],
   "source": [
    "result_dict=dict()\n",
    "EPOCHS = 500 #0\n",
    "past_history = 4\n",
    "\n",
    "for index in INDEX_SHEET_NAME:\n",
    "    print(f\"Start {index} part!\")\n",
    "    result_dict[index] = dict()\n",
    "\n",
    "    data_dir = f'../data/interim/{index}'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raw = load_data(sheet_name=index)\n",
    "        generate_features(raw, index)\n",
    "    \n",
    "    train_lst = os.listdir(data_dir)\n",
    "    train_lst.sort()\n",
    "    for name in train_lst:\n",
    "        x_train = np.load(data_dir + f'/{name}/X_train.npy')\n",
    "        y_train = np.load(data_dir + f'/{name}/Y_train.npy')\n",
    "        x_val = np.load(data_dir + f'/{name}/X_val.npy')\n",
    "        y_val = np.load(data_dir + f'/{name}/Y_val.npy')\n",
    "        x_test = np.load(data_dir + f'/{name}/X_test.npy')\n",
    "        y_test = np.load(data_dir + f'/{name}/Y_test.npy')\n",
    "\n",
    "        train_data, val_data, test_data = generate_train_val_data(\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "            past_history=4, batch_size=60\n",
    "        )\n",
    "\n",
    "\n",
    "        model_save_dir = f'../models/{index}/{name}'\n",
    "        config_filename = '/lstm_config.json'\n",
    "        weight_filename = '/lstm_weights.h5'\n",
    "\n",
    "        if not os.path.exists(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "        if not os.path.exists(model_save_dir+config_filename) \\\n",
    "            or not os.path.exists(model_save_dir+weight_filename):\n",
    "            print(\"No existing model, start to train!\")\n",
    "            lstm = build_lstm_model(inputs_shape=[4, 19],\n",
    "                                    layers=5,\n",
    "                                    units=[64, 64, 64, 64, 64],\n",
    "                                    learning_rate=0.05)\n",
    "            lstm.fit(train_data,\n",
    "                     epochs=EPOCHS,\n",
    "                     steps_per_epoch=(y_train.shape[0] // 60),\n",
    "                     validation_data=val_data,\n",
    "                     validation_steps=1,\n",
    "                     verbose=0)\n",
    "            json_config = lstm.to_json()\n",
    "\n",
    "            with open(model_save_dir+config_filename, 'w') as json_file:\n",
    "                json_file.write(json_config)\n",
    "            # Save weights to disk\n",
    "            lstm.save_weights(model_save_dir+weight_filename)\n",
    "            print(\"Model Saved!\")\n",
    "        else:\n",
    "            with open(model_save_dir+config_filename) as json_file:\n",
    "                json_config = json_file.read()\n",
    "            lstm = tf.keras.models.model_from_json(json_config)\n",
    "            lstm.compile(loss='mse',\n",
    "                              optimizer='Adam',\n",
    "                              metrics=[\n",
    "                                  tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "                                  MeanAbsolutePercentageError(),\n",
    "                                  LinearCorrelation(),\n",
    "                                  TheilU()],\n",
    "                              lr=0.05\n",
    "                              )\n",
    "            lstm.load_weights(model_save_dir+weight_filename)\n",
    "\n",
    "            print(\"Model Loaded!\")\n",
    "\n",
    "        result_dict[index][name] = lstm.evaluate(test_data, steps=1)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        print(f\">>>>{index} {name} done!<<<<\")\n",
    "    try:\n",
    "        with open(f'./lstm/{index}_train_result.pickle', 'wb') as handle:\n",
    "            pickle.dump(result_dict[index], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print('fail to save!')\n",
    "\n",
    "with open(f'./lstm/train_result.pickle', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
